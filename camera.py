import cv2
import numpy as np
from PIL import Image
from keras import models
import os

# Load the saved model
model = models.load_model('/Users/michal/Desktop/leapGestRecog/model.h5')
video = cv2.VideoCapture(0)

count = 0
count1 = 0


lookup = dict()
reverselookup = dict()
count = 0
for j in os.listdir('/Users/michal/Desktop/leapGestRecog/00/'):
    if not j.startswith('.'):  # If running this code locally, this is to
        # avoid reading hidden folders
        lookup[j] = count
        reverselookup[count] = j
        count = count + 1
lookup
while True:

    _, frame = video.read()

    # Convert the captured frame into Greyscale
    im = Image.fromarray(frame, 'RGB')
    im = im.convert('L')

    # Resizing into 320x120 because we trained the model with this image size.

    im = im.resize((320, 120))
    img_array = np.array(im)
    img_array = np.array(img_array, dtype='float32')
    img_array = img_array.reshape((120, 320, 1))

    # Our keras model used following array : (images x height x width x channel)
    # So changing dimension to 1x320x120x1

    img_array = np.expand_dims(img_array, axis=0)
    img_array /= 255

    # Calling the predict method on model to predict gesture

    prediction = model.predict(img_array)

    # Printing out gesture every 10th iteration to avoid spam
    # Selecting max value from table generated by predict (table  with 10 floats->gestures)
    if count1 == 10:
        max=0
        for i in range(10):
            if prediction[0][i] > max:
                a = i
                max=prediction[0][i]

        gesture = reverselookup[a]

    # Printing gesture name and predict generated table contents
        print(prediction)
        print(gesture)
        count1=0

    count1=count1+1

    # Showing camera and listening to key press 'q' that stops program
    cv2.imshow('gesture', frame)
    key = cv2.waitKey(1)
    if key == ord('q'):
        break
video.release()
cv2.destroyAllWindows()